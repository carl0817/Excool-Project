{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmlee/.conda/envs/encoding/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from nilearn import glm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.io import loadmat \n",
    "import h5py\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.signal import convolve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layername = ['/conv1','/conv2','/conv3','/conv4','/conv5','/fc6','/fc7','/fc8']\n",
    "dataroot = '/local_raid3/03_user/jungmin/02_data/Encoding_decoding/encoding_analyzing/02_Goal-Driven-DL/01_NeuralEncodingDecoding/sourcecode/source_code_v2/source_code_v2/feature_extracted/'\n",
    "saveroot = '/local_raid3/03_user/jungmin/02_data/Encoding_decoding/encoding_analyzing/02_Goal-Driven-DL/01_NeuralEncodingDecoding/sourcecode/source_code_v2/source_code_v2/jmlee/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the temporal mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmlee/.conda/envs/encoding/lib/python3.7/site-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  if __name__ == \"__main__\":\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2514707/135194706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mlay_feat_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mlay_feat_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlay_feat_mean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "for lay in range(1,len(layername)):\n",
    "    N = 0\n",
    "    for seg in range (1,18):\n",
    "        secpath = dataroot + 'AlexNet_feature_maps_seg'+ str(seg)+'.h5'\n",
    "        secpath = dataroot + 'AlexNet_feature_maps_seg'+ str(seg)+'.h5'\n",
    "        if os.path.isfile(secpath):\n",
    "            lay_feat = h5py.File(secpath, 'r')\n",
    "            lay_feat = lay_feat[layername[lay] + '/data']            \n",
    "            lay_feat = lay_feat.value\n",
    "            dim = lay_feat.shape\n",
    "            dim = np.asarray(dim)\n",
    "            print(dim.shape)\n",
    "            if seg == 1: \n",
    "                lay_feat_mean = np.zeros((dim[1:],1))\n",
    "            lay_feat_mean = lay_feat_mean + sum(lay_feat,len(dim))\n",
    "            N = N  + dim\n",
    "    lay_feat_mean = lay_feat_mean/N\n",
    "    foldpath = saveroot + 'AlexNet_feature_maps_avg_2' + str(lay)+'.h5'\n",
    "    f = h5py.File(foldpath, 'w')\n",
    "    g = f.create_group(layername[lay])\n",
    "    data = g.create_dataset(\"data\", data=lay_feat_mean)\n",
    "    print(\"Saved: {}\".format(foldpath))\n",
    "    f.close()\n",
    "    \n",
    "    # h5create([dataroot,'AlexNet_feature_maps_avg.h5'],[layername{lay},'/data'],...\n",
    "    #     [size(lay_feat_mean)],'Datatype','single');\n",
    "    # h5write([dataroot,'AlexNet_feature_maps_avg.h5'], [layername{lay},'/data'], lay_feat_mean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 55, 55)\n"
     ]
    }
   ],
   "source": [
    "dir = '/local_raid3/03_user/jungmin/02_data/Encoding_decoding/encoding_analyzing/02_Goal-Driven-DL/01_NeuralEncodingDecoding/sourcecode/source_code_v2/source_code_v2/feature_extracted/AlexNet_feature_maps_avg.h5'\n",
    "feature_avg = h5py.File(dir , 'r')\n",
    "print(feature_avg['/conv1/data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = []\n",
    "for i in range(100):\n",
    "    r = np.corrcoef(lay_feat_mean[:,:,i].ravel(), feature_avg[:,:,i].ravel())[0,1]\n",
    "    a_list.append(r)\n",
    "    \n",
    "print(np.mean(a_list))\n",
    "# print(np.array_equal(lay_feat_mean, feature_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the temporal standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lay in range(1,len(layername)):\n",
    "    lay_feat_mean = h5py.File(secpath + 'AlexNet_feature_maps_avg.h5' + layername(lay) + '/data', 'r')\n",
    "    N = 0\n",
    "    for seg in range (1,18):\n",
    "        print('Seg: ',  str(seg) , '; Layer: ',layername(lay))\n",
    "        secpath = dataroot + 'AlexNet_feature_maps_seg'+ str(seg)+'.h5'\n",
    "        if os.path.isfile(secpath):   \n",
    "            lay_feat = h5py.File(secpath + layername(lay) + '/data', 'r')\n",
    "            lay_feat = np.apply_along_axis(lay_feat_mean - lay_feat)\n",
    "            lay_feat = lay_feat **2 \n",
    "            dim = lay_feat.shape\n",
    "            if seg == 1: \n",
    "                lay_feat_mean = np.zeros([dim[1:1:-1]])\n",
    "            lay_feat_std = lay_feat_std + sum(lay_feat,len(dim))\n",
    "            N = N  + dim\n",
    "    lay_feat_std = np.sqrt(lay_feat_std/(N-1)) \n",
    "    lay_feat_std[lay_feat_std==0] = 1\n",
    "    foldpath = dataroot + 'AlexNet_feature_maps_std' + str(lay)+'.h5'\n",
    "    f = h5py.File(foldpath, 'w')\n",
    "    g = f.create_group(layername[lay])\n",
    "    data = g.create_dataset(\"data\", data= lay_feat_std)\n",
    "    print(\"Saved: {}\".format(foldpath))\n",
    "    f.close()\n",
    "    \n",
    "    # lay_feat_std(lay_feat_std==0) = 1;\n",
    "    # h5create([dataroot,'AlexNet_feature_maps_std.h5'],[layername{lay},'/data'],...\n",
    "    #     [size(lay_feat_mean)],'Datatype','single');\n",
    "    # h5write([dataroot,'AlexNet_feature_maps_std.h5'], [layername{lay},'/data'], lay_feat_std);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD-updating algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Niter = 2 # number of iteration to compute principle component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jlee_amri_sig_isvd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lay in range(1,len(layername)):\n",
    "    lay_feat_mean = h5py.File(secpath + 'AlexNet_feature_maps_avg.h5' + layername(lay) + '/data', 'r')\n",
    "    lay_feat_std = h5py.File(secpath + 'AlexNet_feature_maps_std.h5' + layername(lay) + '/data', 'r')\n",
    "    \n",
    "    k0 = 0\n",
    "    percp = 0.99\n",
    "    for iter in range(1,Niter): \n",
    "        for seg in range (1,18):\n",
    "            print(['Layer: ', str(lay),'; Seg: ',str(seg),'; Comp:',str(k0)])\n",
    "            secpath = dataroot + 'AlexNet_feature_maps_seg'+ str(seg)+'.h5'\n",
    "            if os.path.isfile(secpath)==2:\n",
    "                lay_feat = h5py.File(secpath + layername(lay) + '/data', 'r')\n",
    "                lay_feat = np.subtract(lay_feat, lay_feat_mean)\n",
    "                lay_feat = np.divide(lay_feat, lay_feat_std)\n",
    "                np.nan_to_num(lay_feat, copy=False)\n",
    "                dim = lay_feat.shape\n",
    "                lay_feat = lay_feat.reshape(np.prod(dim[:-1]),dim[-1],order='F').copy()\n",
    "                # lay_feat = bsxfun(@minus, lay_feat, lay_feat_mean);\n",
    "                # lay_feat = bsxfun(@rdivide, lay_feat, lay_feat_std);\n",
    "                # lay_feat(isnan(lay_feat)) = 0; % assign 0 to nan values\n",
    "                # dim = size(lay_feat);\n",
    "                # lay_feat = reshape(lay_feat, prod(dim(1:end-1)),dim(end));\n",
    "                if (seg == 1) and (iter == 1): \n",
    "                    [B, S, k0] = amri_sig_isvd(lay_feat, 'var', percp)\n",
    "                else :\n",
    "                    [B, S, k0] = amri_sig_isvd(lay_feat, 'var',  percp, 'init', {B,S})\n",
    "                \n",
    "            else :\n",
    "                print('file doesn''t exist')\n",
    "    s = np.diag(S)\n",
    "    \n",
    "    # save principal components\n",
    "    foldpath = dataroot +'AlexNet_feature_maps_svd_layer' + str(lay)+'.h5'\n",
    "    f = h5py.File(foldpath, 'w')\n",
    "    g = f.create_group(layername[lay])\n",
    "    data = g.create_dataset(\"B\", data=B)\n",
    "    data = g.create_dataset(\"S\", data=S)\n",
    "    print(\"Saved: {}\".format(foldpath))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layername = {'/conv1';'/conv2';'/conv3';'/conv4';'/conv5';'/fc6';'/fc7';'/fc8'}\n",
    "dataroot = '/local_raid3/03_user/jungmin/02_data/Encoding_decoding/encoding_analyzing/02_Goal-Driven-DL/01_NeuralEncodingDecoding/sourcecode/source_code_v2/source_code_v2/feature_extracted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srate = 30\n",
    "p  = [5, 16, 1, 1, 6, 0, 32]\n",
    "tr = 1/srate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as N\n",
    "\n",
    "def spm_hrf(TR,p=[5,16,1,1,6,0,32]):\n",
    "    \"\"\" An implementation of spm_hrf.m from the SPM distribution\n",
    "Arguments:\n",
    "Required:\n",
    "TR: repetition time at which to generate the HRF (in seconds)\n",
    "Optional:\n",
    "p: list with parameters of the two gamma functions:\n",
    "                                                     defaults\n",
    "                                                    (seconds)\n",
    "   p[0] - delay of response (relative to onset)         6\n",
    "   p[1] - delay of undershoot (relative to onset)      16\n",
    "   p[2] - dispersion of response                        1\n",
    "   p[3] - dispersion of undershoot                      1\n",
    "   p[4] - ratio of response to undershoot               6\n",
    "   p[5] - onset (seconds)                               0\n",
    "   p[6] - length of kernel (seconds)                   32\n",
    "\"\"\"\n",
    "\n",
    "    p=[float(x) for x in p]\n",
    "\n",
    "    fMRI_T = 16.0\n",
    "\n",
    "    TR=float(TR)\n",
    "    dt  = TR/fMRI_T\n",
    "    u   = N.arange(p[6]/dt + 1) - p[5]/dt\n",
    "    hrf=scipy.stats.gamma.pdf(u,p[0]/p[2],scale=1.0/(dt/p[2])) - scipy.stats.gamma.pdf(u,p[1]/p[3],scale=1.0/(dt/p[3]))/p[4]\n",
    "    good_pts=N.array(range(N.int(p[6]/TR)))*int(fMRI_T)\n",
    "    hrf=hrf[list(good_pts)]    \n",
    "    hrf = hrf/N.sum(hrf)\n",
    "    return hrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poldrack_hrf = spm_hrf(tr,p)\n",
    "print(poldrack_hrf.shape)\n",
    "\n",
    "poldrack_hrf = np.expand_dims(poldrack_hrf, -1)\n",
    "print(poldrack_hrf.shape)\n",
    "\n",
    "print(poldrack_hrf.dtype)\n",
    "poldrack_hrf = np.array(poldrack_hrf, dtype=np.float32)\n",
    "print(poldrack_hrf.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in range(1,18):\n",
    "    secpath = dataroot + 'AlexNet_feature_maps_seg'+ str(seg)+'.h5'\n",
    "    if (secpath,'file')==2 :\n",
    "            lay_feat = h5py.File(secpath + layername(lay) + '/data', 'r')\n",
    "            lay_feat = np.subtract(lay_feat, lay_feat_mean)\n",
    "            lay_feat = np.divide(lay_feat, lay_feat_std)\n",
    "            np.nan_to_num(lay_feat, copy=False)\n",
    "            dim = lay_feat.shape\n",
    "            lay_feat = lay_feat.reshape(np.prod(dim[:-1]),dim[-1],order='F').copy() \n",
    "            Y = lay_feat*B/np.sqrt((B,1).shape) #Y: #time-by-#components\n",
    "            Nf = (Y,1).shape\n",
    "            ts = convolve(poldrack_hrf, lay_feat)\n",
    "            ts = ts[4*srate+1:4*srate+Nf, :]\n",
    "            down_sample_idx = np.arange(srate+1, len(ts), srate*2)\n",
    "            ts = ts[down_sample_idx]\n",
    "            print(\"Down sampled ts: {}\".format(ts.shape))\n",
    "            \n",
    "            foldpath = dataroot+'AlexNet_feature_maps_pcareduced_seg' + str(seg)+'.h5'\n",
    "            f = h5py.File(foldpath, 'w')\n",
    "            g = f.create_group(layername[lay])\n",
    "            data = g.create_dataset(\"data\", data=ts)\n",
    "            print(\"Saved: {}\".format(foldpath))\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in range(1,18):\n",
    "    secpath = dataroot + 'AlexNet_feature_maps_test'+ str(seg)+'.h5'\n",
    "    if (secpath,'file')==2 :\n",
    "            lay_feat = h5py.File(secpath + layername(lay) + '/data', 'r')\n",
    "            lay_feat = np.subtract(lay_feat, lay_feat_mean)\n",
    "            lay_feat = np.divide(lay_feat, lay_feat_std)\n",
    "            np.nan_to_num(lay_feat, copy=False)\n",
    "            dim = lay_feat.shape\n",
    "            lay_feat = lay_feat.reshape(np.prod(dim[:-1]),dim[-1],order='F').copy() \n",
    "            Y = lay_feat*B/np.sqrt((B,1).shape) #Y: #time-by-#components\n",
    "            Nf = (Y,1).shape\n",
    "            ts = convolve(poldrack_hrf, lay_feat)\n",
    "            ts = ts[4*srate+1:4*srate+Nf, :]\n",
    "            down_sample_idx = np.arange(srate+1, len(ts), srate*2)\n",
    "            ts = ts[down_sample_idx]\n",
    "            print(\"Down sampled ts: {}\".format(ts.shape))\n",
    "            \n",
    "            foldpath = dataroot+'AlexNet_feature_maps_pcareduced_test' + str(seg)+'.h5'\n",
    "            f = h5py.File(foldpath, 'w')\n",
    "            g = f.create_group(layername[lay])\n",
    "            data = g.create_dataset(\"data\", data=ts)\n",
    "            print(\"Saved: {}\".format(foldpath))\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layername = {'/conv1';'/conv2';'/conv3';'/conv4';'/conv5';'/fc6';'/fc7';'/fc8'}\n",
    "dataroot = '/local_raid3/03_user/jungmin/02_data/Encoding_decoding/encoding_analyzing/02_Goal-Driven-DL/01_NeuralEncodingDecoding/sourcecode/source_code_v2/source_code_v2/feature_extracted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lay in len(layername):\n",
    "    for seg in range(1,18):\n",
    "            secpath = dataroot + 'AlexNet_feature_maps_pcareduced_seg'+ str(seg)+'.h5'     \n",
    "            lay_feat = h5py.File(secpath + layername(lay) + '/data', 'r')\n",
    "            dim = lay_feat.shape\n",
    "            Nf = dim[0] # number of frames\n",
    "            if seg == 1:\n",
    "                Y = np.zeros([Nf*18, dim(2)],'single') \n",
    "            Y[(seg-1)*Nf+1:seg*Nf, :] = lay_feat\n",
    "    \n",
    "    foldpath = dataroot+'AlexNet_feature_maps_pcareduced_concatenated.h5' + str(seg)+'.h5'\n",
    "    f = h5py.File(foldpath, 'w')\n",
    "    g = f.create_group(layername[lay])\n",
    "    data = g.create_dataset(\"data\", data=Y)\n",
    "    print(\"Saved: {}\".format(foldpath))\n",
    "    f.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5dd3353f92ef7bf5a9ab1afe39a0a052fbc7416b62b53b2960209cd1d8a595e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('encoding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
